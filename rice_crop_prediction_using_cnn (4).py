# -*- coding: utf-8 -*-
"""RICE CROP PREDICTION USING CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pc724vuPPHxulxBmyYIa84jMWlLemgno
"""

base_dir = '/content/drive/MyDrive/Rice Crop Dataset/'

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.applications import VGG16
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Suppress TensorFlow logging
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Enable memory growth for the GPU
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
for device in physical_devices:
    tf.config.experimental.set_memory_growth(device, True)

# Directory containing the dataset
base_dir = '/content/drive/MyDrive/Rice Crop Dataset/'
categories = ['Rice__Bacterialblight', 'Rice__Blast', 'Rice__Brownspot', 'Rice__Healthy']

# Load dataset
def load_images(base_dir, categories, img_size=(128, 128)):
    images = []
    labels = []
    for category in categories:
        category_path = os.path.join(base_dir, category)
        for filename in os.listdir(category_path):
            if filename.endswith(".jpg") or filename.endswith(".jpeg") or filename.endswith(".png"):
                img_path = os.path.join(category_path, filename)
                img = cv2.imread(img_path)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img = cv2.resize(img, img_size)
                images.append(img)
                labels.append(category)
    return np.array(images), np.array(labels)

images, labels = load_images(base_dir, categories)

# Display sample images
def display_sample_images(images, labels, class_names):
    plt.figure(figsize=(10, 10))
    for i in range(9):
        idx = np.random.randint(len(images))
        plt.subplot(3, 3, i + 1)
        plt.imshow(images[idx])
        plt.title(class_names[labels[idx]])
        plt.axis('off')
    plt.show()

# Data Preprocessing
le = LabelEncoder()
labels_encoded = le.fit_transform(labels)
labels_encoded = to_categorical(labels_encoded)

# Normalize images
images = images / 255.0

class_names = le.classes_
display_sample_images(images, labels_encoded.argmax(axis=1), class_names)

# Split data
X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

datagen.fit(X_train)

# Build the CNN model
from tensorflow.keras.layers import Conv2D, MaxPooling2D # Importing the necessary layers

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(categories), activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.add(Dense(len(categories), activation='softmax'))

# Train the model with callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)

history = model.fit(datagen.flow(X_train, y_train, batch_size=32),
                    validation_data=(X_test, y_test),
                    epochs=70,
                    callbacks=[early_stopping, reduce_lr])

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

# Generate predictions
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
class_report = classification_report(y_true, y_pred_classes, target_names=class_names)
print('Classification Report:')
print(class_report)

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss')

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')

plt.show()

# Evaluate Model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TensorFlow Lite model
with open('rice_disease_classifier.tflite', 'wb') as f:
  f.write(tflite_model)

# Assuming test_gen is your test data generator, get the number of samples in the test set
# ... (Rest of your existing code) ...

# Define data generators for training, validation, and testing sets
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

valid_datagen = ImageDataGenerator()  # No augmentation for validation and test

test_datagen = ImageDataGenerator()

# Create data generators for training, validation, and test sets
train_gen = train_datagen.flow(X_train, y_train, batch_size=32)
valid_gen = valid_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)  # shuffle=False for evaluation
test_gen = test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)  # shuffle=False for evaluation


#Instead of using test_gen.filenames which is causing the error, we'll use the shape of X_test to determine the number of samples
ts_length = X_test.shape[0]
# Calculate the batch size for the test set
test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length % n == 0 and ts_length / n <= 80]))
# Calculate the number of steps for the test set
test_steps = ts_length // test_batch_size

# Evaluate the model on the training, validation, and test sets
train_score = model.evaluate(train_gen, steps=test_steps, verbose=1)
valid_score = model.evaluate(valid_gen, steps=test_steps, verbose=1)
test_score = model.evaluate(test_gen, steps=test_steps, verbose=1)

# Print the evaluation results
print("Train Loss: ", train_score[0])
print("Train Accuracy: ", train_score[1])
print('-' * 20)
print("Validation Loss: ", valid_score[0])
print("Validation Accuracy: ", valid_score[1])
print('-' * 20)
print("Test Loss: ", test_score[0])
print("Test Accuracy: ", test_score[1])

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming you have already calculated train_score, valid_score, and test_score

# Create a dictionary to store the metrics
metrics_data = {
    'Dataset': ['Train', 'Validation', 'Test'],
    'Loss': [train_score[0], valid_score[0], test_score[0]],
    'Accuracy': [train_score[1], valid_score[1], test_score[1]]
}

# Create a pandas DataFrame from the dictionary
metrics_df = pd.DataFrame(metrics_data)

# Display the table
print(metrics_df.to_string(index=False))  # index=False to hide the index column


# Create graphs for Loss and Accuracy
plt.figure(figsize=(12, 4))

# Loss Graph
plt.subplot(1, 2, 1)
sns.barplot(x='Dataset', y='Loss', data=metrics_df)
plt.title('Loss Comparison')

# Accuracy Graph
plt.subplot(1, 2, 2)
sns.barplot(x='Dataset', y='Accuracy', data=metrics_df)
plt.title('Accuracy Comparison')

plt.tight_layout()
plt.show()

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss')

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')

plt.show()

from tensorflow.keras.models import load_model
import h5py
model.save("rice_disease_model.h5")#Save the model itself and not the weights. This can be converted to TFLite
model.save_weights("rice_disease_model_weights.weights.h5")   #Save the model weights. This cannot be converted to TFLite

print("Saved model to disk")
#If you get the following error: ImportError: DLL load failed while importing _errors: The specified procedure could not be found.
#Run pip install h5py==3.9.0

import numpy as np
import matplotlib.pyplot as plt

# Assuming you have X_test, y_test, and class_names defined

# Generate predictions
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Display some predictions
plt.figure(figsize=(10, 10))
for i in range(9):  # Display 9 images
    idx = np.random.randint(len(X_test))
    plt.subplot(3, 3, i + 1)
    plt.imshow(X_test[idx])
    plt.title(f"Predicted: {class_names[y_pred_classes[idx]]}\nActual: {class_names[y_true[idx]]}")
    plt.axis('off')

plt.show()

import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Enable dynamic range quantization
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_model = converter.convert()

# Save the quantized TensorFlow Lite model
with open('rice_disease_classifier_quantized.tflite', 'wb') as f:
  f.write(tflite_model)

print("Quantized model saved to: rice_disease_classifier_quantized.tflite")